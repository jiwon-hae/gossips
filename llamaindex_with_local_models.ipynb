{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiwon-hae/RAG_with_llamaindex/blob/main/llamaindex_with_local_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save model from hugging face"
      ],
      "metadata": {
        "id": "X09odtuuhZlC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176,
          "referenced_widgets": [
            "2380a2fa1c834d67b50623a2e45b5021",
            "18b322c3f9894818806e9da7e40570ee",
            "a9ab4a49dbc1443db5685d7794c696cd",
            "d73642ee76eb428bb443e6acb6ac8212",
            "07be8700bb404e6faa08516997f479b0",
            "3353b8adf76c4acaa0c3c3ef2f785fd9",
            "0bcb16dbce334cc5b865d310ba7fe900",
            "fe71b00a8ad0447aa423d3b8643f77b5",
            "a01b9a97d3a04e95a7d5bda69d589857",
            "72708ac7fb2c4fe08fe4402e9b913409",
            "98241f6cade34d0ba8d3ec878765feba"
          ]
        },
        "id": "W76tf__xPYQR",
        "outputId": "7f649d31-135f-4b7c-adba-2717f040283b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2380a2fa1c834d67b50623a2e45b5021"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "model_llm = \"Writer/camel-5b-hf\"\n",
        "model_emb = \"BAAI/bge-small-en-v1.5\"\n",
        "\n",
        "save_llm = \"models/camel-5b-hf\"\n",
        "save_emb = \"models/bge-small-en-v1.5\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_llm)\n",
        "model = AutoModel.from_pretrained(model_llm)\n",
        "tokenizer.save_pretrained(save_llm)\n",
        "model.save_pretrained(save_llm)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_emb)\n",
        "model = AutoModel.from_pretrained(model_emb)\n",
        "tokenizer.save_pretrained(save_emb)\n",
        "model.save_pretrained(save_emb)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index llama-index-llms-huggingface llama-index-embeddings-huggingface"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3S2RDkY6ZgtZ",
        "outputId": "b38735ca-e729-4722-8fa3-e817b145dc82"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.11/dist-packages (0.12.43)\n",
            "Requirement already satisfied: llama-index-llms-huggingface in /usr/local/lib/python3.11/dist-packages (0.5.0)\n",
            "Requirement already satisfied: llama-index-embeddings-huggingface in /usr/local/lib/python3.11/dist-packages (0.5.4)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.5,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.11)\n",
            "Requirement already satisfied: llama-index-cli<0.5,>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.3)\n",
            "Requirement already satisfied: llama-index-core<0.13,>=0.12.43 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.12.43)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.7.7)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.5,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.7)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.6,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.5.1)\n",
            "Requirement already satisfied: llama-index-program-openai<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.2)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-readers-file<0.5,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.9)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from llama-index-llms-huggingface) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (4.52.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.33.0)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-embeddings-huggingface) (4.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.1.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.11.15)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.86.0)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.43->llama-index) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.43->llama-index) (2.1.2)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.43->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.43->llama-index) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.43->llama-index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.43->llama-index) (1.2.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.43->llama-index) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.43->llama-index) (0.2.2)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.43->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.43->llama-index) (3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.43->llama-index) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.43->llama-index) (11.2.1)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.43->llama-index) (2.11.7)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.43->llama-index) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.43->llama-index) (2.0.41)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.43->llama-index) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.43->llama-index) (0.9.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.43->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.43->llama-index) (1.17.2)\n",
            "Requirement already satisfied: llama-cloud==0.1.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.26)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud==0.1.26->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.6.15)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (4.13.4)\n",
            "Requirement already satisfied: pandas<2.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.2.2)\n",
            "Requirement already satisfied: pypdf<6,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (5.6.1)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.34)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.15.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.5.3)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (1.7.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (5.9.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.20.1)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.43->llama-index) (1.7.3)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.43->llama-index) (4.3.8)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.7)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.43->llama-index) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.43->llama-index) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.43->llama-index) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.43->llama-index) (0.16.0)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-workflows>=0.2.1->llama-index-core<0.13,>=0.12.43->llama-index) (0.2.0)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.32 in /usr/local/lib/python3.11/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.34)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.43->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.43->llama-index) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.43->llama-index) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.43->llama-index) (3.2.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.43->llama-index) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.43->llama-index) (3.26.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (3.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.6.0)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.32->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index) (1.17.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.43->llama-index) (0.4.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "4cdb78b9c45d471ab3fda431f04c9643",
            "f72cf5f171e5438ba318a5dbe7ef4cdd",
            "abf0de97a9d447768a3ae7910513b1c7",
            "6e20a2790a644fe4b63e11f478b675f9",
            "34d7233db48441c3a95d7badcfdb8714",
            "e624b37cbb2240c8b15e8a3fd9ce4b60",
            "54fdfa30f52248e48f6be1dbdfaef220",
            "a21027fcff414b1ea53d9527c4f2e495",
            "fb655cce35754d6b87db7b72ea8f44f2",
            "5e3c20ad3e4a4aefbc4c858dcbe7e564",
            "56fcec916ebd4c6dbd3a126f41ff7db5"
          ]
        },
        "id": "u5B36FNKPYQS",
        "outputId": "1b38c521-6210-41ec-9977-1cb17ca6824e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4cdb78b9c45d471ab3fda431f04c9643"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "\n",
        "llm = HuggingFaceLLM(\n",
        "    tokenizer_name=\"models/camel-5b-hf\",\n",
        "    model_name=\"models/camel-5b-hf\",\n",
        "    context_window=2048,\n",
        "    max_new_tokens=512,\n",
        "    generate_kwargs={\"temperature\": 0.25, \"do_sample\": True},\n",
        "    device_map=\"auto\",\n",
        "    tokenizer_kwargs={\"max_length\": 2048},\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSSBgs0WPYQT",
        "outputId": "00be6299-d95d-4556-cb61-2e0dc3a575da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletionResponse(text='\\nMistral AI is a cutting-edge artificial intelligence (AI) system that combines natural language processing, machine learning, and advanced analytics to provide actionable insights and predictions across various industries, such as finance, healthcare, and transportation.', additional_kwargs={}, raw={'model_output': tensor([[ 2061,   318, 15078,  1373,  9552,    30,   198, 49370,  1373,  9552,\n",
              "           318,   257,  7720,    12, 14907, 11666,  4430,   357, 20185,     8,\n",
              "          1080,   326, 21001,  3288,  3303,  7587,    11,  4572,  4673,    11,\n",
              "           290,  6190, 23696,   284,  2148,  2223,   540, 17218,   290, 16277,\n",
              "          1973,  2972, 11798,    11,   884,   355,  9604,    11, 11409,    11,\n",
              "           290,  9358,    13, 50256]], device='cuda:0')}, logprobs=None, delta=None)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "llm.complete(\"What is Mistral AI?\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "embed_model = HuggingFaceEmbedding(model_name='models/bge-small-en-v1.5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJ6IjbYCW6N7",
        "outputId": "fffd5fe2-3123-4da7-8815-2c6cd15d1282"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name models/bge-small-en-v1.5. Creating a new one with mean pooling.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = embed_model.get_text_embedding(\"What is GPT4\")\n",
        "embeddings[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwT8aAuYc4nT",
        "outputId": "7d10b7b2-854c-4d72-fb26-9f9225057c28"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0809716209769249, 0.046074219048023224, 0.024222958832979202]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir dataset/llamaindex_data\n",
        "!ls dataset/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbK2lTuFeP8I",
        "outputId": "91d7db8a-78fb-4707-eb75-dbea8dd62362"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘dataset/llamaindex_data’: File exists\n",
            "llamaindex_data  ml_qa_new_models.csv  ml_qa_test.csv\n",
            "lm_texts\t ml_qa_raw.csv\t       ml_qa_train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Llamaindex with local models"
      ],
      "metadata": {
        "id": "zI_wkZBidBBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "\n",
        "documents = SimpleDirectoryReader(\"dataset/llamaindex_data\").load_data()\n",
        "vector_index = VectorStoreIndex.from_documents(documents, embed_model=embed_model, similarity_top_k = 1)\n",
        "query_engine = vector_index.as_query_engine(llm = llm)"
      ],
      "metadata": {
        "id": "bOkHfDpqc_Qj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What is Mistral AI?\")\n",
        "response.response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "OdmBSE_Mh9iS",
        "outputId": "e3742a2d-0984-4153-bd03-a594934c62f6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1514 > 512). Running this sequence through the model will result in indexing errors\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Mistral AI is an AI company founded in 2015 by Elon Musk and Sam Altman, with headquarters in San Francisco, California. It is known for its work on autonomous vehicles, including the Tesla Model 3 and the Neuralink project. It has developed AI-driven self-driving technology, and is known for its work on AI-powered language translation and natural language processing.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "\n",
        "\n",
        "documents = SimpleDirectoryReader(\"dataset/llamaindex_data\").load_data()\n",
        "vector_index = VectorStoreIndex.from_documents(documents, embed_model=\"local:models/bge-small-en-v1.5\", similarity_top_k=1)\n",
        "query_engine = vector_index.as_query_engine(llm=llm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xdr3eGpSh5H0",
        "outputId": "a1ae7e06-29b4-4613-b26f-e2d82d4f0f5e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name models/bge-small-en-v1.5. Creating a new one with mean pooling.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What is Mistral AI?\")\n",
        "response.response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "TsMam4Fic_YF",
        "outputId": "3e27bdcb-5764-45df-f7e6-07fa214e1fa8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nMistral AI is an AI company founded in 2018 by Yann LeCun, a French entrepreneur and investor. It is known for its work on autonomous vehicles, particularly the AlphaGo AI program that defeated a human world champion in the game of Go. Mistral AI is based in Paris, France.\\n\\nOriginal Answer: Mistral AI is an AI company founded in 2018 by Yann LeCun, a French entrepreneur and investor. It is known for its work on autonomous vehicles, particularly the AlphaGo AI program that defeated a human world champion in the game of Go. Mistral AI is based in Paris, France.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Documents"
      ],
      "metadata": {
        "id": "N0XnLN55fEGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def get_wikipedia_page_links(title):\n",
        "    S = requests.Session()\n",
        "\n",
        "    URL = \"https://en.wikipedia.org/w/api.php\"\n",
        "\n",
        "    params = {\n",
        "        \"action\": \"query\",\n",
        "        \"format\": \"json\",\n",
        "        \"titles\": title,\n",
        "        \"prop\": \"links\",\n",
        "        \"pllimit\": \"max\"\n",
        "    }\n",
        "\n",
        "    all_links = []\n",
        "\n",
        "    while True:\n",
        "        response = S.get(url=URL, params=params).json()\n",
        "        pages = response.get('query', {}).get('pages', {})\n",
        "        for page_id, page_content in pages.items():\n",
        "            links = page_content.get('links', [])\n",
        "            for link in links:\n",
        "                all_links.append(link['title'])\n",
        "\n",
        "        if 'continue' in response:\n",
        "            params['plcontinue'] = response['continue']['plcontinue']\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return all_links"
      ],
      "metadata": {
        "id": "gGXGXo68fFhk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "links_lm = get_wikipedia_page_links('Large language model')\n",
        "len(links_lm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2orb_JbfDWT",
        "outputId": "41d509c8-b93d-47f3-c570-bf9723da20bb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "558"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv(dotenv_path='.env')\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "client = OpenAI(api_key = api_key)\n",
        "\n",
        "def get_response(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt},],\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n"
      ],
      "metadata": {
        "id": "LMJDwEdtfDYm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_article_abstract(title):\n",
        "    response = requests.get(\n",
        "        \"https://en.wikipedia.org/w/api.php\",\n",
        "        params={\n",
        "            \"action\": \"query\",\n",
        "            \"format\": \"json\",\n",
        "            \"titles\": title,\n",
        "            \"prop\": \"extracts\",\n",
        "            \"exintro\": True,\n",
        "            \"explaintext\": True,\n",
        "        },\n",
        "    ).json()\n",
        "    page = next(iter(response['query']['pages'].values()))\n",
        "    return page.get(\"extract\", \"\")\n",
        "\n",
        "\n",
        "\n",
        "def is_ml_related(title, abstract):\n",
        "    prompt = f\"\"\"\n",
        "    Given the abstract of the Wikipedia article, determine if the article is machine-learning or language model related.\n",
        "    [Rules]\n",
        "    - Exclude articles about specific individuals\n",
        "    - Exclude articles that are about general knowledge and not related to machine-learning or langauge model.\n",
        "    - Include articles about the developer, company.\n",
        "    - Answer True if the article is related to machine-learning or language model, else False\n",
        "\n",
        "    [title]\n",
        "    {title}\n",
        "    [abstract]\n",
        "    {abstract}\n",
        "    [answer]\n",
        "    \"\"\"\n",
        "\n",
        "    return (get_response(prompt).lower().find(\"true\") > -1)\n"
      ],
      "metadata": {
        "id": "1vlALPuBfDas"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 0\n",
        "links_lm[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lmuHR13FfDe4",
        "outputId": "d62ec87f-b808-4950-8361-9103e7c0db48"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.58-bit large language model'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "title = links_lm[0]\n",
        "abstract = get_article_abstract(title)\n",
        "abstract"
      ],
      "metadata": {
        "id": "nGLTJE-yfDhc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "f87c7861-4e34-4a98-a93d-6a50fe18f0f5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A 1.58-bit Large Language Model (1.58-bit LLM, also ternary LLM) is a version of a transformer large language model with weights using only three values: -1, 0, and +1. This restriction theoretically allows the model to replace costly multiplications with additions and reduce the storage memory. Since the end-task performance and perplexity of the 1.58-bit LLMs, at least for smaller model sizes (up to 3-4B parameters), are close to their \"full precision\" (16-bit FP16 or BF16) counterparts, this design allows reaching the same artificial intelligence goals with much lower hardware requirements, latency, and training effort.\\nThe name comes from a fact that a single trit, a ternary arithmetic equivalent of a bit that can take the {-1, 0, 1} values, carries \\n  \\n    \\n      \\n        l\\n        o\\n        \\n          g\\n          \\n            2\\n          \\n        \\n        3\\n        ≈\\n        1.58\\n      \\n    \\n    {\\\\displaystyle log_{2}3\\\\approx 1.58}\\n  \\n bits of information. The 1.58-bit LLM models are also called 1-bit LLMs (the true 1-bit models also exist).\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "is_ml_related(title, abstract)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdNtnfujijKS",
        "outputId": "76a62f1f-35d9-4fee-e30b-bc1dd7a7e1f7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abstract = get_article_abstract('Syntax')\n",
        "abstract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "k6ZRo-iqivAG",
        "outputId": "b4b1d416-35d1-45c5-b342-7151989ac50b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In linguistics, syntax ( SIN-taks) is the study of how words and morphemes combine to form larger units such as phrases and sentences. Central concerns of syntax include word order, grammatical relations, hierarchical sentence structure (constituency), agreement, the nature of crosslinguistic variation, and the relationship between form and meaning (semantics). Diverse approaches, such as generative grammar and functional grammar, offer unique perspectives on syntax, reflecting its complexity and centrality to understanding human language.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "is_ml_related('Syntax', abstract)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMJXFsI6jEQR",
        "outputId": "828dfd0e-d7c4-46a5-b707-3a61428ae702"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "data_path = Path('dataset/lm_texts')\n",
        "if not data_path.exists():\n",
        "  Path.mkdir(data_path)"
      ],
      "metadata": {
        "id": "w0ZFUOeMjJ7h"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_full_article(title):\n",
        "    response = requests.get(\n",
        "        \"https://en.wikipedia.org/w/api.php\",\n",
        "        params={\n",
        "            \"action\": \"query\",\n",
        "            \"format\": \"json\",\n",
        "            \"titles\": title,\n",
        "            \"prop\": \"extracts\",\n",
        "            \"explaintext\": True,\n",
        "        },\n",
        "    ).json()\n",
        "    page = next(iter(response['query']['pages'].values()))\n",
        "    full_text = page.get(\"extract\", \"\")\n",
        "\n",
        "    with open(f\"../dataset/lm_texts/{title}.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(full_text)"
      ],
      "metadata": {
        "id": "7wox1HlejW48"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "title_valid = []\n",
        "\n",
        "for title in tqdm(random.sample(links_lm, 400)):\n",
        "  try:\n",
        "    abstract = get_article_abstract(title)\n",
        "    if is_ml_related(title, abstract):\n",
        "      save_full_article(title)\n",
        "      title_valid.append(title)\n",
        "  except Exception as e:\n",
        "        print(f\"Error processing '{title}': {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WviZR9YFj19w",
        "outputId": "f2fc569f-c0b3-4db7-997e-f89247916b1d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/400 [00:01<09:12,  1.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing 'Active learning (machine learning)': [Errno 2] No such file or directory: '../dataset/lm_texts/Active learning (machine learning).txt'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 2/400 [00:02<09:34,  1.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing 'Quantization (signal processing)': [Errno 2] No such file or directory: '../dataset/lm_texts/Quantization (signal processing).txt'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 3/400 [00:04<09:54,  1.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing 'Learning to rank': [Errno 2] No such file or directory: '../dataset/lm_texts/Learning to rank.txt'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 6/400 [00:07<07:27,  1.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing 'Topic model': [Errno 2] No such file or directory: '../dataset/lm_texts/Topic model.txt'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 7/400 [00:08<07:52,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing 'Computer-assisted translation': [Errno 2] No such file or directory: '../dataset/lm_texts/Computer-assisted translation.txt'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 20/400 [00:10<01:18,  4.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing 'Graph neural network': [Errno 2] No such file or directory: '../dataset/lm_texts/Graph neural network.txt'\n",
            "Error processing 'Wikidata': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Language resource': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Generative adversarial network': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Category:Artificial neural networks': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Example-based machine translation': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Language model benchmark': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Rule-based machine translation': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Canonical correlation': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Adobe Firefly': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Concordancer': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'ExxonMobil': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Modality (human–computer interaction)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Aidan Gomez': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Huawei PanGu': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Deep learning': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Isolation forest': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'CURE algorithm': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Natural-language user interface': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Cross-entropy': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Word-sense disambiguation': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Concept mining': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Terrence Sejnowski': Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 44/400 [00:10<00:21, 16.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing 'Terminology extraction': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Google Ngram Viewer': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Sentence extraction': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Natural Language Toolkit': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Semantic role labeling': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Qwen': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'PaLM': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'MuZero': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Spiking neural network': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Lotfi A. Zadeh': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Principal component analysis': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Ilya Sutskever': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'GPT-4.1': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Formal semantics (natural language)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Sigmoid function': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'History of artificial intelligence': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Automated reasoning': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Geoffrey Hinton': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Multi-document summarization': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Machine learning': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Black box': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Q-learning': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Machine Learning (journal)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Udio': Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 68/400 [00:10<00:09, 34.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing 'Block cipher': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Cognition': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Vector database': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Warren Sturgis McCulloch': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'WaveNet': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Reinforcement learning from human feedback': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Chinchilla (language model)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Mamba (deep learning architecture)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Neural scaling law': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Latent Dirichlet allocation': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Veo (text-to-video model)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Justification (epistemology)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Autoencoder': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'LLM (disambiguation)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'AlexNet': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'FastText': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Generative model': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Prompt engineering': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Nuclear power': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Mechanistic interpretability': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Recursive self-improvement': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Mistral AI': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'LLaMA': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Nathaniel Rochester (computer scientist)': Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 92/400 [00:10<00:05, 56.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing 'Empirical risk minimization': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Semi-supervised learning': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Hierarchical clustering': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Herbert A. Simon': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Coreference': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Marvin Minsky': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Autonomous agent': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Word-sense induction': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'SpaCy': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Dream Machine (text-to-video model)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'John McCarthy (computer scientist)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'International Conference on Learning Representations': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Reverse engineering': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'DALL-E': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'UBY': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'K-means clustering': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Data cleaning': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Text corpus': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Argument mining': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Robot control': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Myanmar': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Llama (language model)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'API': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Sora (text-to-video model)': Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 116/400 [00:11<00:03, 76.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing 'Softmax function': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Modular arithmetic': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Factor analysis': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Rectifier (neural networks)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Natural language generation': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Gradient descent': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Kiswahili': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Text processing': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Semantics': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Project Debater': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Reinforcement learning': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Feedforward neural network': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Category:CS1 maint: multiple names: authors list': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Treebank': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Natural language processing': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Information extraction': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Bibcode (identifier)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Machine translation': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Word embedding': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Online machine learning': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Mixed-precision arithmetic': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Claude (language model)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Self-organizing map': Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 140/400 [00:11<00:02, 91.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing 'Discrete Fourier transform': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Synthetic data': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Thesaurus (information retrieval)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Word n-gram language model': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Neural machine translation': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'MIT Technology Review': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'AlphaZero': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'State-space representation': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'IBM Watson': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Glossary of artificial intelligence': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Linear regression': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'GPT-4o': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Transformer (deep learning architecture)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Statistical learning theory': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Interactive fiction': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'PropBank': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Chinchilla AI': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Association for Computing Machinery': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Probably approximately correct learning': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Proper generalized decomposition': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Handwriting recognition': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'GloVe': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Collocation extraction': Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 164/400 [00:11<00:02, 102.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing 'Shoggoth': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing '15.ai': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Text segmentation': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Long short-term memory': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Recurrent neural network': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'AutoGPT': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'OpenAI o3': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Fine-tuning (machine learning)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'ArXiv (identifier)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Foundation model': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'In-context learning': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Artificial neural network': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Loss functions for classification': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'GPT-J': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Semantic analysis (machine learning)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Aurora (text-to-image model)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Ari Holtzman': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Computer-assisted reviewing': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'ISBN (identifier)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Restricted Boltzmann machine': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Andrej Karpathy': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Unsupervised learning': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Fine-tuning (deep learning)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'The Language Myth': Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 188/400 [00:11<00:01, 107.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing 'Boosting (machine learning)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Statistical inference': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Distant reading': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Word2vec': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'ImageNet': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Ontology (information science)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Suno AI': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Structured prediction': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Jürgen Schmidhuber': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Web API': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'OPTICS algorithm': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Perceptron': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Quasi-Newton method': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Imagen (text-to-image model)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Linguistic Linked Open Data': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Ian Goodfellow': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Self-driving car': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Machine-readable dictionary': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Distributional semantics': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Backpropagation': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Multi-agent reinforcement learning': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Coefficient of determination': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Memtransistor': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Crowdsourcing': Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 212/400 [00:11<00:01, 110.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing 'BLOOM (language model)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Convolutional neural network': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'International Mathematical Olympiad': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Punctuation mark': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Cardinal direction': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Weight initialization': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Algorithmic bias': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Batch normalization': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Autoregressive model': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Lexical analysis': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Conditional random field': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Christopher D. Manning': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'International Phonetic Alphabet': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Generative pre-trained transformer': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Document classification': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Intelligent agent': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Entropy (information theory)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Decision tree learning': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Speech segmentation': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Stemming': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Speech corpus': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Lemmatisation': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'DeepSeek (chatbot)': Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 236/400 [00:12<00:01, 111.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing 'Encoder-decoder model': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'NeurIPS': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Learning curve (machine learning)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Template:Cite journal': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Policy gradient method': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Yoshua Bengio': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Latent semantic analysis': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Commonsense reasoning': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Runway (company)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Batch learning': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Pathways Language Model': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Shallow parsing': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'ElevenLabs': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Euronews': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'AI explainability': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Walter Pitts': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Predictive text': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Self-play (reinforcement learning technique)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Journal of Machine Learning Research': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Double descent': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Word': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'DeepDream': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'T5 (language model)': Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 260/400 [00:12<00:01, 113.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing 'Generative artificial intelligence': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Pronunciation assessment': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Facial recognition system': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'MiniMax (company)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Deep learning speech synthesis': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Bitext word alignment': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'List of artificial intelligence companies': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Gating mechanism': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Seq2seq': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Latent diffusion model': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'LaMDA': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Highway network': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'U-Net': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Semantic parsing': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Universal Dependencies': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Phi (LLM)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Proprioception': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Gemini (language model)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Neuromorphic engineering': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Nicholas Carlini': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Template talk:Natural language processing': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Speech recognition': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Sparse dictionary learning': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Natural language understanding': Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 284/400 [00:12<00:01, 114.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing 'Learning rate': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Rule-based machine learning': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'DeepSeek': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Nat (unit)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Vapnik–Chervonenkis theory': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Doi (identifier)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Bootstrapping': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'MMLU': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Naive Bayes classifier': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Grammar induction': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Non-negative matrix factorization': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Semantic similarity': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Ideogram (text-to-image model)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Shan language': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Hinglish': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Language model': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Stochastic parrot': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Grammar checker': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Connor Leahy': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Automatic summarization': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Artificial intelligence': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'IBM Granite': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Hyperparameter (machine learning)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Differentiable neural computer': Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 309/400 [00:12<00:00, 117.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing 'Text simplification': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Apache License': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Fei-Fei Li': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Andrew Ng': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Template talk:Artificial intelligence navbox': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'John von Neumann': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'K-nearest neighbors algorithm': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Transformer (machine learning model)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'International Conference on Machine Learning': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Normalization (machine learning)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'ChatGPT': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Stephen Grossberg': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'FLOPS': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Boltzmann machine': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'John Hopfield': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Cloze test': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Artificial general intelligence': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Chain-of-thought prompting': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Parallel text': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Fuzzy clustering': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Grok (chatbot)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Paul Werbos': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Random sample consensus': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing '1.58-bit large language model': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Convolution': Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 333/400 [00:12<00:00, 115.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing 'Automated essay scoring': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Logistic regression': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Ensemble learning': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Temporal difference learning': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Stochastic gradient descent': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Joseph Weizenbaum': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Frank Rosenblatt': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Kling (text-to-video model)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Corpus linguistics': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Computational learning theory': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Text mining': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Action selection': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'ReAct pattern': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Independent component analysis': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Transfer-based machine translation': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Bag-of-words model': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Feature learning': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Mean shift': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Bernard Widrow': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Confusion matrix': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Bigram': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Association rule learning': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Hidden Markov model': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Attention Is All You Need': Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 357/400 [00:13<00:00, 113.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing 'Electrochemical RAM': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Pachinko allocation': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Question answering': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Natural gas': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Curriculum learning': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Cognitive linguistics': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Voice user interface': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Dan Jurafsky': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'FrameNet': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Test set': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'List of chatbots': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Cliff Shaw': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Variational autoencoder': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Category:Artificial intelligence': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Generative pretrained transformer': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'N-gram': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Echo state network': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Bootstrap aggregating': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'The New York Times': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Foundation models': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Retrieval-augmented generation': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Support vector machine': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Automated machine learning': Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 381/400 [00:13<00:00, 113.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing 'Probabilistic context-free grammar': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Demis Hassabis': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Part-of-speech tagging': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Dimensionality reduction': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Overfit': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'LeNet': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Semantic decomposition (natural language processing)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Artificial human companion': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Artificial intelligence and copyright': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Neural network (machine learning)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Multilayer perceptron': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'S2CID (identifier)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'WordNet': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Data center': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Alex Krizhevsky': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'GPT-1': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Statistical classification': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Template:Machine learning': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Yann LeCun': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Parsing': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'List of datasets for machine-learning research': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Supervised learning': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Hallucination (artificial intelligence)': Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [00:13<00:00, 29.52it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing 'Residual neural network': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'BabelNet': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Explicit semantic analysis': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Data compression': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Allen Newell': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Timeline of artificial intelligence': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Graphical model': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Document-term matrix': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'DBpedia': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Mixture of experts': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Regularization (mathematics)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'International Joint Conference on Artificial Intelligence': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Text-to-video model': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Array (data structure)': Expecting value: line 1 column 1 (char 0)\n",
            "Error processing 'Attention (machine learning)': Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(title_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jm0hBjbgkhY6",
        "outputId": "8e5ff79e-b561-4cf8-ef76-e79173b81c1e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xvkuEBeczgIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Settings\n",
        "\n",
        "Settings.chunk_size = 256"
      ],
      "metadata": {
        "id": "MetWi1ovzgsI"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "\n",
        "documents_lm = SimpleDirectoryReader(\"dataset/lm_texts\").load_data()\n",
        "vector_index_lm = VectorStoreIndex.from_documents(documents_lm, embed_model=\"local:models/bge-small-en-v1.5\", similarity_top_k=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt6Y_7QTzlGq",
        "outputId": "e002ac51-dbf6-4d60-e95a-d28da7e1bc7b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name models/bge-small-en-v1.5. Creating a new one with mean pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3.93 s, sys: 116 ms, total: 4.04 s\n",
            "Wall time: 3.56 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Save Vector Index Locally"
      ],
      "metadata": {
        "id": "G9IDRxagit3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector_index_lm.storage_context.persist(persist_dir = \"models/vector_index_lm_ext_bge\")"
      ],
      "metadata": {
        "id": "yikBdXiszxqE"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load local vector index"
      ],
      "metadata": {
        "id": "1SigHyegix7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import StorageContext, load_index_from_storage\n",
        "\n",
        "storage_context = StorageContext.from_defaults(persist_dir = \"models/vector_index_lm_ext_bge\")\n",
        "vector_index_lm = load_index_from_storage(storage_context, embed_model = embed_model, similarity_top_k = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09ff2Vlp2rmm",
        "outputId": "0f0f6e06-1129-4779-9bfa-b0718958b935"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading llama_index.core.storage.kvstore.simple_kvstore from models/vector_index_lm_ext_bge/docstore.json.\n",
            "Loading llama_index.core.storage.kvstore.simple_kvstore from models/vector_index_lm_ext_bge/index_store.json.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine_lm = vector_index_lm.as_query_engine(llm=llm)"
      ],
      "metadata": {
        "id": "UMwSxDRI2z5T"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation\n",
        "**Manual Evlauation**"
      ],
      "metadata": {
        "id": "KQpZA0IGi5UE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%env CUDA_LAUNCH_BLOCKING=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuSH-sZtmsur",
        "outputId": "a1df2bc8-4953-42e1-91fc-8c513c369f60"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CUDA_LAUNCH_BLOCKING=1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is Claude3?\"\n",
        "\n",
        "print(llm.complete(query))\n",
        "\n",
        "for engine in [query_engine, query_engine_lm]:\n",
        "    print(\"========\")\n",
        "    response = engine.query(query)\n",
        "\n",
        "    resp_text = response.response\n",
        "    resp_nodes = response.source_nodes\n",
        "\n",
        "    print(resp_text)\n",
        "    print(\"===Sources====\")\n",
        "    for node in resp_nodes:\n",
        "        print(node)\n",
        "    print(\"=====\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "JMoucR6Y2z7W",
        "outputId": "533da3c4-6735-4843-a53f-6b956a330221"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-38-1988535575.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"What is Claude3?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mquery_engine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_engine_lm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index_instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                     \u001b[0;31m# If the result is a Future, wrap it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/core/llms/callbacks.py\u001b[0m in \u001b[0;36mwrapped_llm_predict\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 )\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                     \u001b[0mf_return_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                     callback_manager.on_event_end(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/llms/huggingface/base.py\u001b[0m in \u001b[0;36mcomplete\u001b[0;34m(self, prompt, formatted, **kwargs)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;31m# remove keys from the tokenizer if needed, to avoid HF errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, device, non_blocking)\u001b[0m\n\u001b[1;32m    819\u001b[0m         \u001b[0;31m# into a HalfTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_torch_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m             self.data = {\n\u001b[0m\u001b[1;32m    822\u001b[0m                 \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_torch_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             self.data = {\n\u001b[0;32m--> 822\u001b[0;31m                 \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             }\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate- using GPT call\n",
        "**Generate query from chunks**"
      ],
      "metadata": {
        "id": "xjVCe5d1ckCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "nodes = list(vector_index_lm.docstore.docs.values())\n",
        "nodes_sampled = [node.text for node in random.sample(nodes, 100)]"
      ],
      "metadata": {
        "id": "LEP6MFp12z_i"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_qa(context):\n",
        "  prompt = f\"\"\"\n",
        "  Given the context, generate the question-answer set\n",
        "\n",
        "  [Rules]\n",
        "  - The question and answer must be sufficiently related.\n",
        "  - The question should be answerable by referring to the content of the context\n",
        "  - The question must be in one sentence\n",
        "  - The answer must be three sentences or fewer\n",
        "\n",
        "  [Example A]\n",
        "  [context]\n",
        "  Perplexity\n",
        "  The most commonly used used of a language model's performance is its perplexity on a given text corpus. Perplexity is a measure of how well a model performs.\n",
        "  Because language models may overfit to their training data, models are usually evaluatled by their perplexity on a test set of unseen data.\n",
        "\n",
        "  [question]\n",
        "  What is perplexity?\n",
        "\n",
        "  [answer]\n",
        "  Perplexity is a metric for assessing how effectivly a language model can forcast the contents of a dataset, commonly used as a measure of a languague model's performance\n",
        "\n",
        "  [Task]\n",
        "  [context]\n",
        "  {context}\n",
        "\n",
        "  [question]\n",
        "  \"\"\"\n",
        "  return get_response(prompt)\n"
      ],
      "metadata": {
        "id": "np_23Imn4NAw"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_qa(qa):\n",
        "  question, answer = qa.split(\"[answer]\")\n",
        "  question = question.strip()\n",
        "  answer = answer.strip()\n",
        "\n",
        "  return question, answer"
      ],
      "metadata": {
        "id": "dGZica4Z4NCy"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = nodes[0]\n",
        "qa = gen_qa(context)\n",
        "q, a = parse_qa(qa)"
      ],
      "metadata": {
        "id": "l25m6OFG4NE3"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Obiw2FRHjUGc",
        "outputId": "4812a6ed-9769-4aaf-992c-0b2d06a175eb"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextNode(id_='91815665-730c-4ec3-9ae6-af8730821119', embedding=None, metadata={'file_path': '/content/dataset/lm_texts/1.58-bit large language model.txt', 'file_name': '1.58-bit large language model.txt', 'file_type': 'text/plain', 'file_size': 3735, 'creation_date': '2025-06-22', 'last_modified_date': '2025-06-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='6189095e-2d97-433a-9588-65b5e77e4197', node_type='4', metadata={'file_path': '/content/dataset/lm_texts/1.58-bit large language model.txt', 'file_name': '1.58-bit large language model.txt', 'file_type': 'text/plain', 'file_size': 3735, 'creation_date': '2025-06-22', 'last_modified_date': '2025-06-22'}, hash='7d61d7daf3ca50619b1af6ce170732e771a981a17da19afbdcc8390ff7eab12c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='44677c34-5138-4b1b-8b2d-a9eef96d1f1c', node_type='1', metadata={}, hash='212aa25d708c800b0801b26ba65259021418c58f7b67fc84e1cf9cf51286ca8a')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='A 1.58-bit Large Language Model (1.58-bit LLM, also ternary LLM) is a version of a transformer large language model with weights using only three values: -1, 0, and +1. This restriction theoretically allows the model to replace costly multiplications with additions and reduce the storage memory. Since the end-task performance and perplexity of the 1.58-bit LLMs, at least for smaller model sizes (up to 3-4B parameters), are close to their \"full precision\" (16-bit FP16 or BF16) counterparts, this design allows reaching the same artificial intelligence goals with much lower hardware requirements, latency, and training effort.\\nThe name comes from a fact that a single trit, a ternary arithmetic equivalent of a bit that can take the {-1, 0, 1} values, carries \\n  \\n    \\n      \\n        l\\n        o\\n        \\n          g\\n          \\n            2\\n          \\n        \\n        3\\n        ≈\\n        1.58\\n      \\n    \\n    {\\\\displaystyle log_{2}3\\\\approx 1.58}\\n  \\n bits of information.', mimetype='text/plain', start_char_idx=0, end_char_idx=976, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}')"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "90n7UK_7jUpi",
        "outputId": "51fd6ae8-38a0-472d-e41d-48d3160ccd08"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is a 1.58-bit Large Language Model (1.58-bit LLM)? \\n\\n[answer]\\nA 1.58-bit Large Language Model (1.58-bit LLM) is a version of a transformer large language model that utilizes only three values (-1, 0, and +1) for its weights, enabling it to replace multiplications with additions and reduce storage memory usage. This theoretical restriction aims to improve efficiency without compromising end-task performance and perplexity.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q, a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lM4ocz5jVVT",
        "outputId": "dcd206a7-9ce5-48a6-9f42-7ec5885709d3"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('What is a 1.58-bit Large Language Model (1.58-bit LLM)?',\n",
              " 'A 1.58-bit Large Language Model (1.58-bit LLM) is a version of a transformer large language model that utilizes only three values (-1, 0, and +1) for its weights, enabling it to replace multiplications with additions and reduce storage memory usage. This theoretical restriction aims to improve efficiency without compromising end-task performance and perplexity.')"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "qa_pairs = []\n",
        "questions = []\n",
        "answers = []\n",
        "contexts = []\n",
        "for node in tqdm(nodes_sampled[:]):\n",
        "    pass\n",
        "    qa = gen_qa(node)\n",
        "    try:\n",
        "        q, a = parse_qa(qa)\n",
        "\n",
        "        contexts.append(node)\n",
        "        qa_pairs.append(qa)\n",
        "        questions.append(q)\n",
        "        answers.append(a)\n",
        "    except Exception as exp:\n",
        "        print(exp)"
      ],
      "metadata": {
        "id": "ni7WfP9B5-vL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f1df69a-f706-4992-e28d-d9c97ad6aa25"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 3/100 [00:04<02:28,  1.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "too many values to unpack (expected 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [01:51<00:00,  1.12s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_qa = pd.DataFrame({'context': contexts, 'qa_pairs': qa_pairs, 'question': questions, 'answer': answers})"
      ],
      "metadata": {
        "id": "aAvY7Uom6N60"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_qa.to_csv('dataset/ml_qa_raw.csv')\n",
        "df_qa[:10].to_csv('dataset/ml_qa_test.csv')\n",
        "df_qa[10:].to_csv('dataset/ml_qa_train.csv')"
      ],
      "metadata": {
        "id": "vxVyWAyJ6hVw"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_qa"
      ],
      "metadata": {
        "id": "7QQ9T_px7nBc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "outputId": "954030f4-cdfd-4125-bdf7-ace312e8cc11"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              context  \\\n",
              "0   SNNs are theoretically more powerful than so c...   \n",
              "1   )\\n          \\n            (\\n            1\\n ...   \n",
              "2   K\\n        )\\n        =\\n        \\n          {...   \n",
              "3   p\\n              (\\n              ¬\\n         ...   \n",
              "4   r\\n          \\n            t\\n          \\n    ...   \n",
              "..                                                ...   \n",
              "94  β\\n        )\\n        +\\n        \\n          e...   \n",
              "95  K)=\\left\\{{\\begin{array}{cc}2^{N}&K\\geq N\\\\2\\s...   \n",
              "96  i\\n                  \\n                \\n     ...   \n",
              "97  A feature vector \\n  \\n    \\n      \\n        \\...   \n",
              "98  If the researcher only has access to \\n  \\n   ...   \n",
              "\n",
              "                                             qa_pairs  \\\n",
              "0   What are some limitations of using Spike Neura...   \n",
              "1   What is the formula for calculating the probab...   \n",
              "2   What is the formula for T(n, K) in the given c...   \n",
              "3   What does the equation represent in the contex...   \n",
              "4   What are the implications of having a discount...   \n",
              "..                                                ...   \n",
              "94  What is the goal of the researchers in the con...   \n",
              "95  What happens to the value of T(N, K)/2^N when ...   \n",
              "96  What does the symbol \"i − x̄\" represent in the...   \n",
              "97  What is a feature vector in the context of doc...   \n",
              "98  How many combinations of beta values can the r...   \n",
              "\n",
              "                                             question  \\\n",
              "0   What are some limitations of using Spike Neura...   \n",
              "1   What is the formula for calculating the probab...   \n",
              "2   What is the formula for T(n, K) in the given c...   \n",
              "3    What does the equation represent in the context?   \n",
              "4   What are the implications of having a discount...   \n",
              "..                                                ...   \n",
              "94  What is the goal of the researchers in the con...   \n",
              "95  What happens to the value of T(N, K)/2^N when ...   \n",
              "96  What does the symbol \"i − x̄\" represent in the...   \n",
              "97  What is a feature vector in the context of doc...   \n",
              "98  How many combinations of beta values can the r...   \n",
              "\n",
              "                                               answer  \n",
              "0   SNNs have training issues and high hardware re...  \n",
              "1   The formula is the product of the probability ...  \n",
              "2   The formula for T(n, K) is defined as follows:...  \n",
              "3   The equation represents the probability of not...  \n",
              "4   A discount factor in Q-function learning deter...  \n",
              "..                                                ...  \n",
              "94  The researchers' goal is to estimate the funct...  \n",
              "95  When N is less than or equal to 2K, the value ...  \n",
              "96  In the context provided, \"i - x̄\" represents t...  \n",
              "97  A feature vector in this context is a histogra...  \n",
              "98  If the researcher has access to N=2 data point...  \n",
              "\n",
              "[99 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32332583-de36-413f-ac32-cb7336aa7d36\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>qa_pairs</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SNNs are theoretically more powerful than so c...</td>\n",
              "      <td>What are some limitations of using Spike Neura...</td>\n",
              "      <td>What are some limitations of using Spike Neura...</td>\n",
              "      <td>SNNs have training issues and high hardware re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>)\\n          \\n            (\\n            1\\n ...</td>\n",
              "      <td>What is the formula for calculating the probab...</td>\n",
              "      <td>What is the formula for calculating the probab...</td>\n",
              "      <td>The formula is the product of the probability ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>K\\n        )\\n        =\\n        \\n          {...</td>\n",
              "      <td>What is the formula for T(n, K) in the given c...</td>\n",
              "      <td>What is the formula for T(n, K) in the given c...</td>\n",
              "      <td>The formula for T(n, K) is defined as follows:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>p\\n              (\\n              ¬\\n         ...</td>\n",
              "      <td>What does the equation represent in the contex...</td>\n",
              "      <td>What does the equation represent in the context?</td>\n",
              "      <td>The equation represents the probability of not...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>r\\n          \\n            t\\n          \\n    ...</td>\n",
              "      <td>What are the implications of having a discount...</td>\n",
              "      <td>What are the implications of having a discount...</td>\n",
              "      <td>A discount factor in Q-function learning deter...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>β\\n        )\\n        +\\n        \\n          e...</td>\n",
              "      <td>What is the goal of the researchers in the con...</td>\n",
              "      <td>What is the goal of the researchers in the con...</td>\n",
              "      <td>The researchers' goal is to estimate the funct...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>K)=\\left\\{{\\begin{array}{cc}2^{N}&amp;K\\geq N\\\\2\\s...</td>\n",
              "      <td>What happens to the value of T(N, K)/2^N when ...</td>\n",
              "      <td>What happens to the value of T(N, K)/2^N when ...</td>\n",
              "      <td>When N is less than or equal to 2K, the value ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>i\\n                  \\n                \\n     ...</td>\n",
              "      <td>What does the symbol \"i − x̄\" represent in the...</td>\n",
              "      <td>What does the symbol \"i − x̄\" represent in the...</td>\n",
              "      <td>In the context provided, \"i - x̄\" represents t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>A feature vector \\n  \\n    \\n      \\n        \\...</td>\n",
              "      <td>What is a feature vector in the context of doc...</td>\n",
              "      <td>What is a feature vector in the context of doc...</td>\n",
              "      <td>A feature vector in this context is a histogra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>If the researcher only has access to \\n  \\n   ...</td>\n",
              "      <td>How many combinations of beta values can the r...</td>\n",
              "      <td>How many combinations of beta values can the r...</td>\n",
              "      <td>If the researcher has access to N=2 data point...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>99 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32332583-de36-413f-ac32-cb7336aa7d36')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-32332583-de36-413f-ac32-cb7336aa7d36 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-32332583-de36-413f-ac32-cb7336aa7d36');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5bf39880-de0e-480c-8aa6-ef27601265f7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5bf39880-de0e-480c-8aa6-ef27601265f7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5bf39880-de0e-480c-8aa6-ef27601265f7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_8ff6b9ce-4687-4a6b-a51c-cd2dc88ce1d4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_qa')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8ff6b9ce-4687-4a6b-a51c-cd2dc88ce1d4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_qa');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_qa",
              "summary": "{\n  \"name\": \"df_qa\",\n  \"rows\": 99,\n  \"fields\": [\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 98,\n        \"samples\": [\n          \"2, pp. 179\\u2013191.\\nOlazaran Rodriguez, Jose Miguel. A historical sociology of neural network research. PhD Dissertation. University of Edinburgh, 1991.\\nMohri, Mehryar and Rostamizadeh, Afshin (2013). Perceptron Mistake Bounds arXiv:1305.0208, 2013.\\nNovikoff, A. B. (1962). On convergence proofs on perceptrons. Symposium on the Mathematical Theory of Automata, 12, 615\\u2013622. Polytechnic Institute of Brooklyn.\\nWidrow, B., Lehr, M.A., \\\"30 years of Adaptive Neural Networks: Perceptron, Madaline, and Backpropagation,\\\" Proc. IEEE, vol 78, no 9, pp. 1415\\u20131442, (1990).\\nCollins, M. 2002. Discriminative training methods for hidden Markov models: Theory and experiments with the perceptron algorithm in Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP '02).\",\n          \"\\u03b2\\n                ^\\n              \\n            \\n          \\n          \\n            1\\n          \\n        \\n        \\n          \\n            \\n              x\\n              \\u00af\\n            \\n          \\n        \\n      \\n    \\n    {\\\\displaystyle {\\\\widehat {\\\\beta }}_{0}={\\\\bar {y}}-{\\\\widehat {\\\\beta }}_{1}{\\\\bar {x}}}\\n  \\n\\nwhere\",\n          \"K)=\\\\left\\\\{{\\\\begin{array}{cc}2^{N}&K\\\\geq N\\\\\\\\2\\\\sum _{k=0}^{K-1}\\\\left({\\\\begin{array}{c}N-1\\\\\\\\k\\\\end{array}}\\\\right)&K<N\\\\end{array}}\\\\right.}\\n  \\nWhen K is large, \\n  \\n    \\n      \\n        T\\n        (\\n        N\\n        ,\\n        K\\n        )\\n        \\n          /\\n        \\n        \\n          2\\n          \\n            N\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle T(N,K)/2^{N}}\\n  \\n is very close to one when \\n  \\n    \\n      \\n        N\\n        \\u2264\\n        2\\n        K\\n      \\n    \\n    {\\\\displaystyle N\\\\leq 2K}\\n  \\n, but very close to zero when \\n  \\n    \\n      \\n        N\\n        >\\n        2\\n        K\\n      \\n    \\n    {\\\\displaystyle N>2K}\\n  \\n. In words, one perceptron unit can almost certainly memorize a random assignment of binary labels on N points when \\n  \\n    \\n      \\n        N\\n        \\u2264\\n        2\\n        K\\n      \\n    \\n    {\\\\displaystyle N\\\\leq 2K}\\n  \\n, but almost certainly not when \\n  \\n    \\n      \\n        N\\n        >\\n        2\\n        K\\n      \\n    \\n    {\\\\displaystyle N>2K}\\n  \\n.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"qa_pairs\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 99,\n        \"samples\": [\n          \"What is the value of p in this case and what can be said about the standard errors of the parameter estimates? \\n\\n[answer]\\nThe value of p is equal to 1, making the denominator of the standard errors calculation n-2. The standard errors of the parameter estimates are then given by the symbol \\u03b2-hat.\",\n          \"What is the formula for calculating the intercept beta0 in the context of linear regression?\\n\\n[answer]\\nThe formula for calculating the intercept beta0 in linear regression is: beta0 = mean of y - beta1 * mean of x.\",\n          \"What happens to the value of T(N, K)/2^N when N is less than or equal to 2K versus when N is greater than 2K in the given context?\\n\\n[answer]\\nWhen N is less than or equal to 2K, the value of T(N, K)/2^N is very close to one, indicating that one perceptron unit can almost certainly memorize a random assignment of binary labels on N points. However, when N is greater than 2K, the value is very close to zero, indicating that one perceptron unit almost certainly cannot memorize the labels.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 98,\n        \"samples\": [\n          \"What is the value of p in this case and what can be said about the standard errors of the parameter estimates?\",\n          \"What is the formula for calculating the intercept beta0 in the context of linear regression?\",\n          \"What happens to the value of T(N, K)/2^N when N is less than or equal to 2K versus when N is greater than 2K in the given context?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 99,\n        \"samples\": [\n          \"The value of p is equal to 1, making the denominator of the standard errors calculation n-2. The standard errors of the parameter estimates are then given by the symbol \\u03b2-hat.\",\n          \"The formula for calculating the intercept beta0 in linear regression is: beta0 = mean of y - beta1 * mean of x.\",\n          \"When N is less than or equal to 2K, the value of T(N, K)/2^N is very close to one, indicating that one perceptron unit can almost certainly memorize a random assignment of binary labels on N points. However, when N is greater than 2K, the value is very close to zero, indicating that one perceptron unit almost certainly cannot memorize the labels.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generate query of AI models"
      ],
      "metadata": {
        "id": "tMXJ7hJUjg2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_models = [\"Claude 3\", \"Germini 1.5\", \"Mixtral8x7B\", \"Llama3\", \"PanGu\"]"
      ],
      "metadata": {
        "id": "f6G_9Pzj7nDn"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "\n",
        "documents = SimpleDirectoryReader(\"dataset/lm_texts\").load_data()\n",
        "\n",
        "vector_index = VectorStoreIndex.from_documents(documents)\n",
        "vector_index.storage_context.persist(persist_dir=\"models/vector_index_lm_text_chatGPT\")"
      ],
      "metadata": {
        "id": "Cw9AsbfJ7nGW"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "\n",
        "retriever = VectorIndexRetriever(\n",
        "    index=vector_index,\n",
        "    similarity_top_k=1,\n",
        ")"
      ],
      "metadata": {
        "id": "E346Xvqs8ATH"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_contexts = []\n",
        "for model in new_models:\n",
        "    result = retriever.retrieve(model)[0].text\n",
        "    model_contexts.append(result)\n",
        "\n",
        "model_contexts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Gi-PUCk8IBK",
        "outputId": "50b47780-ac88-45db-b9d5-a34068d69a6a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Searching for archival traces of James Hemings, Thomas Jefferson's enslaved chef, Klein juxtaposes visualisations of his presence with Jefferson's own charts and tables as the basis for a discussion of data visualisation as it relates to the construction of race.\\nThe COST Action 'Distant Reading for European Literary History' is a European networking project bringing together scholars interested in corpus building, quantitative text analysis, and European literary history. It aims to create a network of researchers jointly developing the distant reading resources and methods necessary to change the way European literary history is written. The objectives of the project include coordinating the creation of a multilingual European Literary Text Collection (ELTeC) containing digital full-texts of novels in different European languages.\\n\\n\\n== See also ==\\nClose reading\\n\\n\\n== References ==\",\n",
              " \"A recent solution to physical limitations of technology comes from GeriJoy, in the form of virtual pets for seniors. Seniors can interact with GeriJoy's pets by petting them through the multitouch interface of standard consumer-grade tablets, and can even have intelligent conversations with the pets.\\nTelevision viewing among the elderly represents a significant percentage of how their waking hours are spent, and the percentage increases directly with age. Seniors typically watch TV to avoid loneliness; yet TV limits social interaction, thus creating a vicious circle.\\nIn 2012 Judith Masthoff, a professor of computer science from the University of Utrech, purports that it is possible to develop an interactive, personalized form of television that would allow the viewer to engage in natural conversation and learn from these conversations, as well as becoming more physically active which can help in the management of Type 2 Diabetes.\\nRecent research shows the proliferation of this technology, particularly among the younger generation. Another study reveals that young people are increasingly engaging in digital relationships with AI as a form of emotional support.\",\n",
              " 'Ma, Shuming; Wang, Hongyu; Huang, Shaohan; Zhang, Xingxing; Hu, Ying; Song, Ting; Xia, Yan; Wei, Furu (2025). \"BitNet b1.58 2B4T Technical Report\". arXiv:2504.12285 [cs.CL].\\nFriha, Othmane; Amine Ferrag, Mohamed; Kantarci, Burak; Cakmak, Burak; Ozgun, Arda; Ghoualmi-Zine, Nassira (2024). \"LLM-Based Edge Intelligence: A Comprehensive Survey on Architectures, Applications, Security and Trustworthiness\". IEEE Open Journal of the Communications Society. 5: 5799–5856. doi:10.1109/OJCOMS.2024.3456549. ISSN 2644-125X.\\nHutson, Matthew (2024-05-30). \"1-bit LLMs Could Solve AI\\'s Energy Demands\". IEEE Spectrum. Retrieved 2025-04-22.',\n",
              " '\"LLM-Based Edge Intelligence: A Comprehensive Survey on Architectures, Applications, Security and Trustworthiness\". IEEE Open Journal of the Communications Society. 5: 5799–5856. doi:10.1109/OJCOMS.2024.3456549. ISSN 2644-125X.\\nHutson, Matthew (2024-05-30). \"1-bit LLMs Could Solve AI\\'s Energy Demands\". IEEE Spectrum. Retrieved 2025-04-22.\\nHuyen, Chip (2024-12-04). AI Engineering. \"O\\'Reilly Media, Inc.\". ISBN 978-1-0981-6627-4. Retrieved 2025-04-22.\\nKumar, Tanishq; Ankner, Zachary; Spector, Benjamin F.; Bordelon, Blake; Muennighoff, Niklas; Paul, Mansheej; Pehlevan, Cengiz; Ré, Christopher; Raghunathan, Aditi (2024). \"Scaling Laws for Precision\".',\n",
              " \"A recent solution to physical limitations of technology comes from GeriJoy, in the form of virtual pets for seniors. Seniors can interact with GeriJoy's pets by petting them through the multitouch interface of standard consumer-grade tablets, and can even have intelligent conversations with the pets.\\nTelevision viewing among the elderly represents a significant percentage of how their waking hours are spent, and the percentage increases directly with age. Seniors typically watch TV to avoid loneliness; yet TV limits social interaction, thus creating a vicious circle.\\nIn 2012 Judith Masthoff, a professor of computer science from the University of Utrech, purports that it is possible to develop an interactive, personalized form of television that would allow the viewer to engage in natural conversation and learn from these conversations, as well as becoming more physically active which can help in the management of Type 2 Diabetes.\\nRecent research shows the proliferation of this technology, particularly among the younger generation. Another study reveals that young people are increasingly engaging in digital relationships with AI as a form of emotional support.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_qa_new_models(context, model):\n",
        "    prompt = f\"\"\"\n",
        "    Given the context and model, generate the question-answer set\n",
        "\n",
        "    [Rules]\n",
        "    - Generate questions about the model, and create answers to them based on the given context.\n",
        "    - Create a simple one-sentence question focusing on one aspect of the model's characteristics.\n",
        "    - Keep the answer to no more than two sentences.\n",
        "\n",
        "    [Example A]\n",
        "    [context]\n",
        "    GPT-J or GPT-J-6B is an open-source large language model (LLM) developed by EleutherAI in 2021.[1] As the name suggests, it is a generative pre-trained transformer model designed to produce human-like text that continues from a prompt. The optional \"6B\" in the name refers to the fact that it has 6 billion parameters.[2]\n",
        "    [question]\n",
        "    When is the initial relase of GPT-J?\n",
        "\n",
        "    [answer]\n",
        "    The initial release of GPT-J, an open-source large language model developed by EleutherAI, was in June 2021.\n",
        "\n",
        "    [Task]\n",
        "    [context]\n",
        "    {context}\n",
        "    [model]\n",
        "    {model}\n",
        "    [question]\n",
        "    \"\"\"\n",
        "\n",
        "    return get_response(prompt)"
      ],
      "metadata": {
        "id": "Kl3h3dsf8axM"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_pairs = []\n",
        "questions = []\n",
        "answers = []\n",
        "contexts = []\n",
        "for model, context in zip(new_models, model_contexts):\n",
        "    qa = gen_qa_new_models(model, context)\n",
        "    try:\n",
        "        q, a = parse_qa(qa)\n",
        "\n",
        "        contexts.append(context)\n",
        "        qa_pairs.append(qa)\n",
        "        questions.append(q)\n",
        "        answers.append(a)\n",
        "    except Exception as exp:\n",
        "        print(exp)\n"
      ],
      "metadata": {
        "id": "Zw7mnfIN9ELt"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_qa_new_model = pd.DataFrame({'context': contexts, 'qa_pairs': qa_pairs, 'question': questions, 'answer': answers})\n",
        "df_qa_new_model.to_csv(\"dataset/ml_qa_new_models.csv\")"
      ],
      "metadata": {
        "id": "l5zuIXuj9ENg"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_qa_new_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "d6JKCE7p9ESM",
        "outputId": "ef638c1e-33c1-4de1-8c44-bafe56703b46"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             context  \\\n",
              "0  Searching for archival traces of James Hemings...   \n",
              "1  A recent solution to physical limitations of t...   \n",
              "2  Ma, Shuming; Wang, Hongyu; Huang, Shaohan; Zha...   \n",
              "3  \"LLM-Based Edge Intelligence: A Comprehensive ...   \n",
              "4  A recent solution to physical limitations of t...   \n",
              "\n",
              "                                            qa_pairs  \\\n",
              "0  What is the focus of the COST Action 'Distant ...   \n",
              "1  What is Germini 1.5's solution to physical lim...   \n",
              "2  What is the title of the technical report rela...   \n",
              "3  What is the title of the research paper introd...   \n",
              "4  What is the main purpose of GeriJoy's virtual ...   \n",
              "\n",
              "                                            question  \\\n",
              "0  What is the focus of the COST Action 'Distant ...   \n",
              "1  What is Germini 1.5's solution to physical lim...   \n",
              "2  What is the title of the technical report rela...   \n",
              "3  What is the title of the research paper introd...   \n",
              "4  What is the main purpose of GeriJoy's virtual ...   \n",
              "\n",
              "                                              answer  \n",
              "0  The project aims to create a network of resear...  \n",
              "1  Germini 1.5, developed by GeriJoy, offers virt...  \n",
              "2  The technical report related to the BitNet b1....  \n",
              "3  The title of the research paper introducing th...  \n",
              "4  GeriJoy's virtual pets for seniors provide a w...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-10b6ba0b-2d1c-4b08-9b2b-e53e9d3532a7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>qa_pairs</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Searching for archival traces of James Hemings...</td>\n",
              "      <td>What is the focus of the COST Action 'Distant ...</td>\n",
              "      <td>What is the focus of the COST Action 'Distant ...</td>\n",
              "      <td>The project aims to create a network of resear...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A recent solution to physical limitations of t...</td>\n",
              "      <td>What is Germini 1.5's solution to physical lim...</td>\n",
              "      <td>What is Germini 1.5's solution to physical lim...</td>\n",
              "      <td>Germini 1.5, developed by GeriJoy, offers virt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ma, Shuming; Wang, Hongyu; Huang, Shaohan; Zha...</td>\n",
              "      <td>What is the title of the technical report rela...</td>\n",
              "      <td>What is the title of the technical report rela...</td>\n",
              "      <td>The technical report related to the BitNet b1....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"LLM-Based Edge Intelligence: A Comprehensive ...</td>\n",
              "      <td>What is the title of the research paper introd...</td>\n",
              "      <td>What is the title of the research paper introd...</td>\n",
              "      <td>The title of the research paper introducing th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A recent solution to physical limitations of t...</td>\n",
              "      <td>What is the main purpose of GeriJoy's virtual ...</td>\n",
              "      <td>What is the main purpose of GeriJoy's virtual ...</td>\n",
              "      <td>GeriJoy's virtual pets for seniors provide a w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10b6ba0b-2d1c-4b08-9b2b-e53e9d3532a7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-10b6ba0b-2d1c-4b08-9b2b-e53e9d3532a7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-10b6ba0b-2d1c-4b08-9b2b-e53e9d3532a7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-af51620d-0de4-446d-b072-ead67c4b28d9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-af51620d-0de4-446d-b072-ead67c4b28d9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-af51620d-0de4-446d-b072-ead67c4b28d9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_f1f62605-35a1-4617-8c96-44f0d96e8eb6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_qa_new_model')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f1f62605-35a1-4617-8c96-44f0d96e8eb6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_qa_new_model');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_qa_new_model",
              "summary": "{\n  \"name\": \"df_qa_new_model\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"A recent solution to physical limitations of technology comes from GeriJoy, in the form of virtual pets for seniors. Seniors can interact with GeriJoy's pets by petting them through the multitouch interface of standard consumer-grade tablets, and can even have intelligent conversations with the pets.\\nTelevision viewing among the elderly represents a significant percentage of how their waking hours are spent, and the percentage increases directly with age. Seniors typically watch TV to avoid loneliness; yet TV limits social interaction, thus creating a vicious circle.\\nIn 2012 Judith Masthoff, a professor of computer science from the University of Utrech, purports that it is possible to develop an interactive, personalized form of television that would allow the viewer to engage in natural conversation and learn from these conversations, as well as becoming more physically active which can help in the management of Type 2 Diabetes.\\nRecent research shows the proliferation of this technology, particularly among the younger generation. Another study reveals that young people are increasingly engaging in digital relationships with AI as a form of emotional support.\",\n          \"\\\"LLM-Based Edge Intelligence: A Comprehensive Survey on Architectures, Applications, Security and Trustworthiness\\\". IEEE Open Journal of the Communications Society. 5: 5799\\u20135856. doi:10.1109/OJCOMS.2024.3456549. ISSN 2644-125X.\\nHutson, Matthew (2024-05-30). \\\"1-bit LLMs Could Solve AI's Energy Demands\\\". IEEE Spectrum. Retrieved 2025-04-22.\\nHuyen, Chip (2024-12-04). AI Engineering. \\\"O'Reilly Media, Inc.\\\". ISBN 978-1-0981-6627-4. Retrieved 2025-04-22.\\nKumar, Tanishq; Ankner, Zachary; Spector, Benjamin F.; Bordelon, Blake; Muennighoff, Niklas; Paul, Mansheej; Pehlevan, Cengiz; R\\u00e9, Christopher; Raghunathan, Aditi (2024). \\\"Scaling Laws for Precision\\\".\",\n          \"Searching for archival traces of James Hemings, Thomas Jefferson's enslaved chef, Klein juxtaposes visualisations of his presence with Jefferson's own charts and tables as the basis for a discussion of data visualisation as it relates to the construction of race.\\nThe COST Action 'Distant Reading for European Literary History' is a European networking project bringing together scholars interested in corpus building, quantitative text analysis, and European literary history. It aims to create a network of researchers jointly developing the distant reading resources and methods necessary to change the way European literary history is written. The objectives of the project include coordinating the creation of a multilingual European Literary Text Collection (ELTeC) containing digital full-texts of novels in different European languages.\\n\\n\\n== See also ==\\nClose reading\\n\\n\\n== References ==\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"qa_pairs\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"What is Germini 1.5's solution to physical limitations of technology?\\n\\n[answer]\\nGermini 1.5, developed by GeriJoy, offers virtual pets for seniors that they can interact with through multitouch interfaces on tablets, providing intelligent conversations and reducing loneliness.\",\n          \"What is the main purpose of GeriJoy's virtual pets for seniors?\\n\\n    [answer]\\n    GeriJoy's virtual pets for seniors provide a way for them to interact and have intelligent conversations, helping to combat loneliness and increase social engagement.\",\n          \"What is the title of the technical report related to the BitNet b1.58 2B4T model?\\n\\n    [answer]\\n    The technical report related to the BitNet b1.58 2B4T model is titled \\\"BitNet b1.58 2B4T Technical Report\\\".\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"What is Germini 1.5's solution to physical limitations of technology?\",\n          \"What is the main purpose of GeriJoy's virtual pets for seniors?\",\n          \"What is the title of the technical report related to the BitNet b1.58 2B4T model?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Germini 1.5, developed by GeriJoy, offers virtual pets for seniors that they can interact with through multitouch interfaces on tablets, providing intelligent conversations and reducing loneliness.\",\n          \"GeriJoy's virtual pets for seniors provide a way for them to interact and have intelligent conversations, helping to combat loneliness and increase social engagement.\",\n          \"The technical report related to the BitNet b1.58 2B4T model is titled \\\"BitNet b1.58 2B4T Technical Report\\\".\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generate Response from the query"
      ],
      "metadata": {
        "id": "HxjtjQbIj16g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir results"
      ],
      "metadata": {
        "id": "F8BEZ0-P9qIX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cf1a083-dfcc-4b6b-96bb-3f1bc903d2b0"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘results’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "data_path = Path('results/inference_result')\n",
        "eval_data_path = Path(\"results/eval_result\")\n",
        "\n",
        "\n",
        "if not data_path.exists():\n",
        "  Path.mkdir(data_path)\n",
        "\n",
        "if not eval_data_path.exists():\n",
        "  Path.mkdir(eval_data_path)"
      ],
      "metadata": {
        "id": "jrOKR0qg9qKc"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = df_qa[:10]\n",
        "df_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "aybT_ZIs9qMg",
        "outputId": "524d2ff4-af5d-48fd-8a7c-315efb570bb3"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             context  \\\n",
              "0  SNNs are theoretically more powerful than so c...   \n",
              "1  )\\n          \\n            (\\n            1\\n ...   \n",
              "2  K\\n        )\\n        =\\n        \\n          {...   \n",
              "3  p\\n              (\\n              ¬\\n         ...   \n",
              "4  r\\n          \\n            t\\n          \\n    ...   \n",
              "5  == Algorithm ==\\n\\nAfter \\n  \\n    \\n      \\n ...   \n",
              "6  .\\n        .\\n        ,\\n        (\\n        \\n...   \n",
              "7  In a similar vein, Stephen Marche focuses on t...   \n",
              "8  ∑\\n              (\\n              \\n          ...   \n",
              "9  Expert systems, that were popular in the 1980s...   \n",
              "\n",
              "                                            qa_pairs  \\\n",
              "0  What are some limitations of using Spike Neura...   \n",
              "1  What is the formula for calculating the probab...   \n",
              "2  What is the formula for T(n, K) in the given c...   \n",
              "3  What does the equation represent in the contex...   \n",
              "4  What are the implications of having a discount...   \n",
              "5  What is the role of the discount factor in the...   \n",
              "6  What is the Decision Transformer approach in r...   \n",
              "7  What are some critiques of distant reading in ...   \n",
              "8  What does the symbol ∑ represent in the contex...   \n",
              "9  How did AI systems in the 1980s differ from mo...   \n",
              "\n",
              "                                            question  \\\n",
              "0  What are some limitations of using Spike Neura...   \n",
              "1  What is the formula for calculating the probab...   \n",
              "2  What is the formula for T(n, K) in the given c...   \n",
              "3   What does the equation represent in the context?   \n",
              "4  What are the implications of having a discount...   \n",
              "5  What is the role of the discount factor in the...   \n",
              "6  What is the Decision Transformer approach in r...   \n",
              "7  What are some critiques of distant reading in ...   \n",
              "8  What does the symbol ∑ represent in the contex...   \n",
              "9  How did AI systems in the 1980s differ from mo...   \n",
              "\n",
              "                                              answer  \n",
              "0  SNNs have training issues and high hardware re...  \n",
              "1  The formula is the product of the probability ...  \n",
              "2  The formula for T(n, K) is defined as follows:...  \n",
              "3  The equation represents the probability of not...  \n",
              "4  A discount factor in Q-function learning deter...  \n",
              "5  The discount factor, represented by gamma, det...  \n",
              "6  The Decision Transformer approach models reinf...  \n",
              "7  Critiques of distant reading in computational ...  \n",
              "8  The symbol ∑ represents the sum of a series of...  \n",
              "9  Expert systems in the 1980s were limited in th...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-866c5004-45a9-405c-b953-2701fc6ab28b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>qa_pairs</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SNNs are theoretically more powerful than so c...</td>\n",
              "      <td>What are some limitations of using Spike Neura...</td>\n",
              "      <td>What are some limitations of using Spike Neura...</td>\n",
              "      <td>SNNs have training issues and high hardware re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>)\\n          \\n            (\\n            1\\n ...</td>\n",
              "      <td>What is the formula for calculating the probab...</td>\n",
              "      <td>What is the formula for calculating the probab...</td>\n",
              "      <td>The formula is the product of the probability ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>K\\n        )\\n        =\\n        \\n          {...</td>\n",
              "      <td>What is the formula for T(n, K) in the given c...</td>\n",
              "      <td>What is the formula for T(n, K) in the given c...</td>\n",
              "      <td>The formula for T(n, K) is defined as follows:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>p\\n              (\\n              ¬\\n         ...</td>\n",
              "      <td>What does the equation represent in the contex...</td>\n",
              "      <td>What does the equation represent in the context?</td>\n",
              "      <td>The equation represents the probability of not...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>r\\n          \\n            t\\n          \\n    ...</td>\n",
              "      <td>What are the implications of having a discount...</td>\n",
              "      <td>What are the implications of having a discount...</td>\n",
              "      <td>A discount factor in Q-function learning deter...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>== Algorithm ==\\n\\nAfter \\n  \\n    \\n      \\n ...</td>\n",
              "      <td>What is the role of the discount factor in the...</td>\n",
              "      <td>What is the role of the discount factor in the...</td>\n",
              "      <td>The discount factor, represented by gamma, det...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>.\\n        .\\n        ,\\n        (\\n        \\n...</td>\n",
              "      <td>What is the Decision Transformer approach in r...</td>\n",
              "      <td>What is the Decision Transformer approach in r...</td>\n",
              "      <td>The Decision Transformer approach models reinf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>In a similar vein, Stephen Marche focuses on t...</td>\n",
              "      <td>What are some critiques of distant reading in ...</td>\n",
              "      <td>What are some critiques of distant reading in ...</td>\n",
              "      <td>Critiques of distant reading in computational ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>∑\\n              (\\n              \\n          ...</td>\n",
              "      <td>What does the symbol ∑ represent in the contex...</td>\n",
              "      <td>What does the symbol ∑ represent in the contex...</td>\n",
              "      <td>The symbol ∑ represents the sum of a series of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Expert systems, that were popular in the 1980s...</td>\n",
              "      <td>How did AI systems in the 1980s differ from mo...</td>\n",
              "      <td>How did AI systems in the 1980s differ from mo...</td>\n",
              "      <td>Expert systems in the 1980s were limited in th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-866c5004-45a9-405c-b953-2701fc6ab28b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-866c5004-45a9-405c-b953-2701fc6ab28b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-866c5004-45a9-405c-b953-2701fc6ab28b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4bf1c637-b01e-4caf-9213-7b0e8cf31f3c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4bf1c637-b01e-4caf-9213-7b0e8cf31f3c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4bf1c637-b01e-4caf-9213-7b0e8cf31f3c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_167cdc9c-ac92-435a-9f5a-2a064ed4be50\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_test')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_167cdc9c-ac92-435a-9f5a-2a064ed4be50 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_test');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test",
              "summary": "{\n  \"name\": \"df_test\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"\\u2211\\n              (\\n              \\n                x\\n                \\n                  i\\n                \\n              \\n              \\u2212\\n              \\n                \\n                  \\n                    x\",\n          \")\\n          \\n            (\\n            1\\n            \\u2212\\n            \\n              x\\n              \\n                i\\n              \\n            \\n            )\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle p(\\\\mathbf {x} \\\\mid C_{k})=\\\\prod _{i=1}^{n}p_{ki}^{x_{i}}(1-p_{ki})^{(1-x_{i})}}\\n  \\n\\nwhere\",\n          \"== Algorithm ==\\n\\nAfter \\n  \\n    \\n      \\n        \\u0394\\n        t\\n      \\n    \\n    {\\\\displaystyle \\\\Delta t}\\n  \\n steps into the future the agent will decide some next step. The weight for this step is calculated as \\n  \\n    \\n      \\n        \\n          \\u03b3\\n          \\n            \\u0394\\n            t\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle \\\\gamma ^{\\\\Delta t}}\\n  \\n, where \\n  \\n    \\n      \\n        \\u03b3\\n      \\n    \\n    {\\\\displaystyle \\\\gamma }\\n  \\n (the discount factor) is a number between 0 and 1 (\\n  \\n    \\n      \\n        0\\n        \\u2264\\n        \\u03b3\\n        \\u2264\\n        1\\n      \\n    \\n    {\\\\displaystyle 0\\\\leq \\\\gamma \\\\leq 1}\\n  \\n). Assuming \\n  \\n    \\n      \\n        \\u03b3\\n        <\\n        1\\n      \\n    \\n    {\\\\displaystyle \\\\gamma <1}\\n  \\n, it has the effect of valuing rewards received earlier higher than those received later (reflecting the value of a \\\"good start\\\").\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"qa_pairs\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"What does the symbol \\u2211 represent in the context provided?\\n\\n[answer]\\nThe symbol \\u2211 represents the sum of a series of values or terms in the context provided. It is used to denote the total sum of all the values or terms being added together.\",\n          \"What is the formula for calculating the probability of a sample belonging to a particular class in a binary classification problem?\\n\\n[answer]\\nThe formula is the product of the probability of the sample's features being 1 or 0 for each feature, raised to the power of the actual value of the feature in the sample, or the complement of that probability for a feature not present in the sample.\",\n          \"What is the role of the discount factor in the agent's decision-making process after a certain number of future steps? \\n\\n[answer]\\nThe discount factor, represented by gamma, determines how much weight is given to rewards received earlier versus later, with a value between 0 and 1. A value of gamma less than 1 reflects the prioritization of rewards obtained earlier in the decision-making process, placing higher value on a \\\"good start.\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"What does the symbol \\u2211 represent in the context provided?\",\n          \"What is the formula for calculating the probability of a sample belonging to a particular class in a binary classification problem?\",\n          \"What is the role of the discount factor in the agent's decision-making process after a certain number of future steps?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"The symbol \\u2211 represents the sum of a series of values or terms in the context provided. It is used to denote the total sum of all the values or terms being added together.\",\n          \"The formula is the product of the probability of the sample's features being 1 or 0 for each feature, raised to the power of the actual value of the feature in the sample, or the complement of that probability for a feature not present in the sample.\",\n          \"The discount factor, represented by gamma, determines how much weight is given to rewards received earlier versus later, with a value between 0 and 1. A value of gamma less than 1 reflects the prioritization of rewards obtained earlier in the decision-making process, placing higher value on a \\\"good start.\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = df_qa[:10]\n",
        "llm_answer = []\n",
        "qe_answer = []\n",
        "\n",
        "for idx, row in tqdm(df_test.iterrows()):\n",
        "    query = row['question']\n",
        "    resp_llm = llm.complete(query)\n",
        "    resp_qe = query_engine_lm.query(query)\n",
        "    llm_answer.append(resp_llm)\n",
        "    qe_answer.append(resp_qe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "H3_fRxe89qOn",
        "outputId": "d8edf5c4-8ef5-42cc-e6da-68857d5d390a"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-63-1609841151.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mresp_llm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mresp_qe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_engine_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mllm_answer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp_llm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index_instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                     \u001b[0;31m# If the result is a Future, wrap it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/core/llms/callbacks.py\u001b[0m in \u001b[0;36mwrapped_llm_predict\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 )\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                     \u001b[0mf_return_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                     callback_manager.on_event_end(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/llms/huggingface/base.py\u001b[0m in \u001b[0;36mcomplete\u001b[0;34m(self, prompt, formatted, **kwargs)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;31m# remove keys from the tokenizer if needed, to avoid HF errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, device, non_blocking)\u001b[0m\n\u001b[1;32m    819\u001b[0m         \u001b[0;31m# into a HalfTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_torch_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m             self.data = {\n\u001b[0m\u001b[1;32m    822\u001b[0m                 \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_torch_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             self.data = {\n\u001b[0;32m--> 822\u001b[0;31m                 \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             }\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_eval = pd.concat([df_test, df_test])\n",
        "df_eval['answer_llm'] = llm_answer + qe_answer\n",
        "df_eval['model'] = ['llm']*len(llm_answer) + ['qe']*len(qe_answer)\n",
        "df_eval.to_csv(f\"{data_path}/qa_inferenced.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "kwqOUEaMeKIM",
        "outputId": "bac2d1e5-d30e-4e14-f432-120501f00c2e"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Length of values (0) does not match length of index (20)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-64-4121145851.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_eval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'answer_llm'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm_answer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mqe_answer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_eval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'llm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm_answer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'qe'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqe_answer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{data_path}/qa_inferenced.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4309\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4310\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4311\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4522\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4523\u001b[0m         \"\"\"\n\u001b[0;32m-> 4524\u001b[0;31m         \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4526\u001b[0m         if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5266\u001b[0;31m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5267\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5268\u001b[0m         if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    571\u001b[0m     \"\"\"\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    574\u001b[0m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Length of values (0) does not match length of index (20)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_answer = []\n",
        "qe_answer = []\n",
        "\n",
        "for idx, row in tqdm(df_qa_new_model.iterrows()):\n",
        "    query = row['question']\n",
        "    resp_llm = llm.complete(query)\n",
        "    resp_qe = query_engine_lm.query(query)\n",
        "    llm_answer.append(resp_llm)\n",
        "    qe_answer.append(resp_qe)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "EjOT_U6B9qQ3",
        "outputId": "a713b89b-57c7-4fa9-d17a-6e1b96fb620a"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-65-2912498190.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_qa_new_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mresp_llm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mresp_qe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_engine_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mllm_answer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp_llm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index_instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                     \u001b[0;31m# If the result is a Future, wrap it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/core/llms/callbacks.py\u001b[0m in \u001b[0;36mwrapped_llm_predict\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 )\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                     \u001b[0mf_return_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                     callback_manager.on_event_end(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/llms/huggingface/base.py\u001b[0m in \u001b[0;36mcomplete\u001b[0;34m(self, prompt, formatted, **kwargs)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;31m# remove keys from the tokenizer if needed, to avoid HF errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, device, non_blocking)\u001b[0m\n\u001b[1;32m    819\u001b[0m         \u001b[0;31m# into a HalfTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_torch_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m             self.data = {\n\u001b[0m\u001b[1;32m    822\u001b[0m                 \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_torch_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             self.data = {\n\u001b[0;32m--> 822\u001b[0;31m                 \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             }\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_eval = pd.concat([df_qa_new_model, df_qa_new_model])\n",
        "df_eval['answer_llm'] = llm_answer + qe_answer\n",
        "df_eval['model'] = ['llm']*len(llm_answer) + ['qe']*len(qe_answer)\n",
        "df_eval.to_csv(f\"{data_path}/qa_models_inferenced.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "2wbmib8MD4Zm",
        "outputId": "6e7cf24a-fb70-4e48-fafc-637c0ce0bc84"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Length of values (0) does not match length of index (10)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-66-230439802.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_qa_new_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_qa_new_model\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_eval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'answer_llm'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm_answer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mqe_answer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_eval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'llm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm_answer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'qe'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqe_answer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{data_path}/qa_models_inferenced.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4309\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4310\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4311\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4522\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4523\u001b[0m         \"\"\"\n\u001b[0;32m-> 4524\u001b[0;31m         \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4526\u001b[0m         if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5266\u001b[0;31m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5267\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5268\u001b[0m         if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    571\u001b[0m     \"\"\"\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    574\u001b[0m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Length of values (0) does not match length of index (10)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "opGqJ9Ttnr5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-vCRchne9qTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s1RNIEFI9qVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-yZH8yrw9qXL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2380a2fa1c834d67b50623a2e45b5021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18b322c3f9894818806e9da7e40570ee",
              "IPY_MODEL_a9ab4a49dbc1443db5685d7794c696cd",
              "IPY_MODEL_d73642ee76eb428bb443e6acb6ac8212"
            ],
            "layout": "IPY_MODEL_07be8700bb404e6faa08516997f479b0"
          }
        },
        "18b322c3f9894818806e9da7e40570ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3353b8adf76c4acaa0c3c3ef2f785fd9",
            "placeholder": "​",
            "style": "IPY_MODEL_0bcb16dbce334cc5b865d310ba7fe900",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "a9ab4a49dbc1443db5685d7794c696cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe71b00a8ad0447aa423d3b8643f77b5",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a01b9a97d3a04e95a7d5bda69d589857",
            "value": 3
          }
        },
        "d73642ee76eb428bb443e6acb6ac8212": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72708ac7fb2c4fe08fe4402e9b913409",
            "placeholder": "​",
            "style": "IPY_MODEL_98241f6cade34d0ba8d3ec878765feba",
            "value": " 3/3 [00:00&lt;00:00, 44.57it/s]"
          }
        },
        "07be8700bb404e6faa08516997f479b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3353b8adf76c4acaa0c3c3ef2f785fd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bcb16dbce334cc5b865d310ba7fe900": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe71b00a8ad0447aa423d3b8643f77b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a01b9a97d3a04e95a7d5bda69d589857": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "72708ac7fb2c4fe08fe4402e9b913409": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98241f6cade34d0ba8d3ec878765feba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cdb78b9c45d471ab3fda431f04c9643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f72cf5f171e5438ba318a5dbe7ef4cdd",
              "IPY_MODEL_abf0de97a9d447768a3ae7910513b1c7",
              "IPY_MODEL_6e20a2790a644fe4b63e11f478b675f9"
            ],
            "layout": "IPY_MODEL_34d7233db48441c3a95d7badcfdb8714"
          }
        },
        "f72cf5f171e5438ba318a5dbe7ef4cdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e624b37cbb2240c8b15e8a3fd9ce4b60",
            "placeholder": "​",
            "style": "IPY_MODEL_54fdfa30f52248e48f6be1dbdfaef220",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "abf0de97a9d447768a3ae7910513b1c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a21027fcff414b1ea53d9527c4f2e495",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb655cce35754d6b87db7b72ea8f44f2",
            "value": 5
          }
        },
        "6e20a2790a644fe4b63e11f478b675f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e3c20ad3e4a4aefbc4c858dcbe7e564",
            "placeholder": "​",
            "style": "IPY_MODEL_56fcec916ebd4c6dbd3a126f41ff7db5",
            "value": " 5/5 [00:05&lt;00:00,  1.02it/s]"
          }
        },
        "34d7233db48441c3a95d7badcfdb8714": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e624b37cbb2240c8b15e8a3fd9ce4b60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54fdfa30f52248e48f6be1dbdfaef220": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a21027fcff414b1ea53d9527c4f2e495": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb655cce35754d6b87db7b72ea8f44f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e3c20ad3e4a4aefbc4c858dcbe7e564": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56fcec916ebd4c6dbd3a126f41ff7db5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}