{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/rag_llamaindex/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from newspaper import Article\n",
    "from collectors.wikipedia import *\n",
    "from collectors.google_news import *\n",
    "from collectors.trends import *\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Trending celebrities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/19/2025 03:10:51 AM - Error converting news item: 'decoded_url'\n",
      "07/19/2025 03:10:52 AM - Error converting news item: 'decoded_url'\n",
      "07/19/2025 03:10:53 AM - Error converting news item: 'decoded_url'\n",
      "07/19/2025 03:10:55 AM - Error converting news item: 'decoded_url'\n",
      "07/19/2025 03:10:56 AM - Error converting news item: 'decoded_url'\n",
      "07/19/2025 03:10:57 AM - Error converting news item: 'decoded_url'\n",
      "07/19/2025 03:10:58 AM - Error converting news item: 'decoded_url'\n",
      "07/19/2025 03:10:59 AM - Error converting news item: 'decoded_url'\n",
      "07/19/2025 03:10:59 AM - Error converting news item: 'decoded_url'\n",
      "07/19/2025 03:11:01 AM - Error converting news item: 'decoded_url'\n",
      "07/19/2025 03:11:02 AM - Error converting news item: 'decoded_url'\n",
      "07/19/2025 03:11:03 AM - Error converting news item: 'decoded_url'\n",
      "07/19/2025 03:11:04 AM - Error converting news item: 'decoded_url'\n",
      "07/19/2025 03:11:05 AM - Error converting news item: 'decoded_url'\n",
      "07/19/2025 03:11:06 AM - Error converting news item: 'decoded_url'\n"
     ]
    }
   ],
   "source": [
    "trendCollector = TrendCollector()\n",
    "trending_celebs = await trendCollector.get_hottest_celebs(limit=100)\n",
    "trending_celebs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get wiki and profile infos via Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting celeb profiles: 0celeb [00:00, ?celeb/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "wikiCollector = WikipediaCollector()\n",
    "profiles = []\n",
    "\n",
    "for name in tqdm(trending_celebs, desc=\"Collecting celeb profiles\", unit=\"celeb\"):\n",
    "    saved = wikiCollector.save_wiki(name)\n",
    "    if not saved:\n",
    "        continue\n",
    "    \n",
    "    profile = wikiCollector.profile(name)\n",
    "    if profile:\n",
    "        profiles.append(profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import asdict\n",
    "\n",
    "profile_dicts = [asdict(p) for p in profiles]\n",
    "celeb_profiles = pd.DataFrame(profile_dicts)\n",
    "celeb_profiles.to_csv('../documents/profiles.csv')\n",
    "celeb_profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Articles for Each “Hot Star”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collectors.google_news import CelebrityGoogleNewsCollector\n",
    "from newspaper import Article\n",
    "\n",
    "news_collector = CelebrityGoogleNewsCollector()\n",
    "news_collected = []\n",
    "\n",
    "base_path = 'articles'\n",
    "\n",
    "\n",
    "def serialize_relation(rel):\n",
    "    data = asdict(rel)\n",
    "    data['relationship'] = data['relationship'].value\n",
    "    data['start_yr'] = rel.start_yr.isoformat() if rel.start_yr else None\n",
    "    data['end_yr'] = rel.end_yr.isoformat() if rel.end_yr else None\n",
    "    return data\n",
    "\n",
    "\n",
    "for p in profiles:\n",
    "    news_list = await news_collector.get_news(p.name, max_results=10)\n",
    "    is_first_married = bool(\n",
    "        p.spouse) and p.spouse[0].relationship == RelationshipStatus.MARRIED\n",
    "    relationships = [serialize_relation(rel)\n",
    "                     for rel in p.spouse] if p.spouse else []\n",
    "\n",
    "    base_md = {\n",
    "        'celeb': p.name,\n",
    "        'occupatin': p.occupation,\n",
    "        'spouse': relationships[0] if is_first_married else None,\n",
    "        'ex_relations': relationships[1:] if is_first_married else relationships\n",
    "    }\n",
    "\n",
    "    for news in news_list:\n",
    "        await news_collector.save_article(\n",
    "            url=news.url, \n",
    "            metadata={'source': news.publisher, **base_md})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_llamaindex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
